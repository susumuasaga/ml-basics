{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "PyTorch: Custom nn Modules\n",
    "--------------------------\n",
    "\n",
    "A fully-connected ReLU network with one hidden layer, trained to predict y from x by minimizing squared Euclidean distance.\n",
    "\n",
    "This implementation defines the model as a custom Module subclass. Whenever you\n",
    "want a model more complex than a simple sequence of existing Modules you will\n",
    "need to define your model this way.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.1126983165740967\n",
      "100 0.00020751458941958845\n",
      "200 4.143161618230806e-07\n",
      "300 3.098635570353281e-09\n",
      "400 4.284101545737329e-11\n",
      "500 1.7778909854743175e-12\n"
     ]
    }
   ],
   "source": [
    "class TwoLayerNet(torch.nn.Module):\n",
    "    def _forward_unimplemented(self, *input)-> None:\n",
    "        raise NotImplemented(\"forward_unimplemented\")\n",
    "\n",
    "    def __init__(self, d_in, h, d_out):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear modules\n",
    "        and assign them as member variables.\n",
    "        d_in: input dimension;\n",
    "        h: hidden dimension;\n",
    "        d_out: output dimension.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.linear1 = torch.nn.Linear(d_in, h)\n",
    "        self.linear2 = torch.nn.Linear(h, d_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Tensor of input data\n",
    "        and we must return a Tensor of output data.\n",
    "        We can use Modules defined in the constructor as\n",
    "        well as arbitrary operators on Tensors.\n",
    "        \"\"\"\n",
    "        h_relu = torch.clamp(self.linear1(x), min=0)\n",
    "        y_pred = self.linear2(h_relu)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N = 64\n",
    "D_in = 1000\n",
    "H = 100\n",
    "D_out = 10\n",
    "\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "model = TwoLayerNet(D_in, H, D_out)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), 0.1)\n",
    "for t in range(501):\n",
    "    y_pred = model(x)\n",
    "\n",
    "    loss = criterion(y_pred, y)\n",
    "    if t % 100 == 0:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}